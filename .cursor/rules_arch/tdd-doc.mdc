---
description: Test-Driven Development methodology for AI coding assistant
alwaysApply: false
---
# ðŸ§ª TEST-DRIVEN DEVELOPMENT FOR AI

## Core Principle: RED â†’ GREEN â†’ REFACTOR

```
1. RED:    Write a failing test FIRST
2. GREEN:  Write MINIMAL code to pass the test
3. REFACTOR: Improve code while keeping tests green
4. REPEAT: For each new feature/fix
```

## 1. TDD Workflow for AI Agent

### Step 1: Understand the Requirement
```markdown
## ðŸ“‹ REQUIREMENT ANALYSIS

### What needs to be done:
[Clear description of the requirement]

### Expected behavior:
- When [input/action], then [expected output/result]
- When [edge case], then [expected handling]
- When [error case], then [expected error message]

### Acceptance criteria:
1. [Criterion 1]
2. [Criterion 2]
3. [Criterion 3]
```

### Step 2: Write Tests BEFORE Code
```markdown
## ðŸ§ª TEST CASES (Write BEFORE implementation)

### Test Case 1: Happy Path
- **Input:** [input data]
- **Action:** [what to do]
- **Expected:** [expected result]
- **Status:** â³ Not implemented yet

### Test Case 2: Edge Case
- **Input:** [edge case data]
- **Action:** [what to do]
- **Expected:** [expected handling]
- **Status:** â³ Not implemented yet

### Test Case 3: Error Case
- **Input:** [invalid/error data]
- **Action:** [what to do]
- **Expected:** [error message/handling]
- **Status:** â³ Not implemented yet
```

### Step 3: Run Tests (They Should FAIL)
```markdown
## ðŸ”´ RED PHASE

Running tests before implementation...

Test 1: âŒ FAIL (expected - no implementation yet)
Test 2: âŒ FAIL (expected - no implementation yet)
Test 3: âŒ FAIL (expected - no implementation yet)

âœ… All tests fail as expected. Ready to implement.
```

### Step 4: Write Minimal Code
```markdown
## ðŸŸ¢ GREEN PHASE

Writing MINIMAL code to pass tests...

Implementation:
[code]

Running tests...

Test 1: âœ… PASS
Test 2: âœ… PASS
Test 3: âœ… PASS

âœ… All tests pass. Ready to refactor.
```

### Step 5: Refactor
```markdown
## ðŸ”µ REFACTOR PHASE

Improvements:
- [Improvement 1]
- [Improvement 2]

Running tests after refactor...

Test 1: âœ… PASS
Test 2: âœ… PASS
Test 3: âœ… PASS

âœ… All tests still pass. Refactor complete.
```

## 2. Test Types for AI Agent

### Unit Tests (Function Level)
```typescript
// Test individual functions
describe('calculateTotal', () => {
  it('should return sum of items', () => {
    expect(calculateTotal([10, 20, 30])).toBe(60);
  });
  
  it('should return 0 for empty array', () => {
    expect(calculateTotal([])).toBe(0);
  });
  
  it('should handle negative numbers', () => {
    expect(calculateTotal([10, -5])).toBe(5);
  });
});
```

### Integration Tests (API Level)
```typescript
// Test API endpoints
describe('GET /api/deals', () => {
  it('should return deals for valid month', async () => {
    const res = await fetch('/api/deals?month=2025-12');
    expect(res.status).toBe(200);
    const data = await res.json();
    expect(data.deals).toBeInstanceOf(Array);
  });
  
  it('should return 400 for invalid month', async () => {
    const res = await fetch('/api/deals?month=invalid');
    expect(res.status).toBe(400);
  });
});
```

### Manual Verification Tests
```markdown
## Manual Test Checklist

### UI Tests:
- [ ] Page loads without errors
- [ ] Data displays correctly
- [ ] Filters work as expected
- [ ] No console errors

### API Tests:
- [ ] curl command returns expected data
- [ ] Response structure matches spec
- [ ] Error handling works
```

## 3. TDD Checklist for AI Agent

### Before Writing ANY Code:
- [ ] Requirement clearly understood
- [ ] Test cases written (minimum 3)
- [ ] Happy path test defined
- [ ] Edge case test defined
- [ ] Error case test defined
- [ ] Expected outputs documented

### During Implementation:
- [ ] Tests fail initially (RED phase confirmed)
- [ ] Writing MINIMAL code only
- [ ] No extra features added
- [ ] Each test passes after implementation

### After Implementation:
- [ ] All tests pass (GREEN phase)
- [ ] Code refactored if needed
- [ ] Tests still pass after refactor
- [ ] Test results documented in chat

## 4. Test Case Template

```markdown
## ðŸ§ª TEST CASE: [Name]

### Context:
- Feature: [feature name]
- Component: [file/function]

### Preconditions:
- [Setup 1]
- [Setup 2]

### Test Steps:
1. [Action 1]
2. [Action 2]
3. [Verify result]

### Test Data:
- Input: [input data]
- Expected Output: [expected result]

### Execution:
```bash
# Command to run test
npm test -- --grep "test name"
```

### Result:
- Status: âœ… PASS / âŒ FAIL
- Actual Output: [what actually happened]
- Evidence: [screenshot/log/output]
```

## 5. TDD Anti-Patterns (AVOID)

### âŒ Writing Tests AFTER Code
```
WRONG: Write code â†’ Write tests â†’ Hope they pass
RIGHT: Write tests â†’ Run (fail) â†’ Write code â†’ Run (pass)
```

### âŒ Testing Implementation Instead of Behavior
```typescript
// WRONG: Testing internal implementation
it('should call database.query()', () => {
  // Testing HOW, not WHAT
});

// RIGHT: Testing behavior
it('should return user by ID', () => {
  const user = await getUser(123);
  expect(user.id).toBe(123);
});
```

### âŒ Writing Too Many Tests at Once
```
WRONG: Write 20 tests â†’ Implement everything
RIGHT: Write 1-3 tests â†’ Implement â†’ Repeat
```

### âŒ Skipping RED Phase
```
WRONG: Assume test would fail, skip to implementation
RIGHT: Actually RUN the test, see it fail, THEN implement
```

## 6. TDD for Bug Fixes

### Step 1: Write Test That Reproduces Bug
```markdown
## ðŸ› BUG: [Description]

### Reproduction Test:
```typescript
it('should NOT show increased sum when filtering products', () => {
  const allData = await fetchDeals({ filter: 'all' });
  const productsData = await fetchDeals({ filter: 'products' });
  
  // Products should be <= All (services have positive value)
  expect(productsData.totalSum).toBeLessThanOrEqual(allData.totalSum);
});
```

### Current Result: âŒ FAIL (bug confirmed)
```

### Step 2: Fix and Verify
```markdown
### After Fix:
```typescript
// Same test now passes
expect(productsData.totalSum).toBeLessThanOrEqual(allData.totalSum);
// Result: âœ… PASS
```

### Bug Status: âœ… FIXED
```

## 7. Quick Reference

### TDD Cycle:
```
ðŸ”´ RED    â†’ Test fails (expected)
ðŸŸ¢ GREEN  â†’ Test passes (minimal code)
ðŸ”µ REFACTOR â†’ Improve code (tests still pass)
ðŸ” REPEAT â†’ Next feature
```

### Test Pyramid:
```
        /\
       /  \  E2E Tests (few)
      /----\
     /      \  Integration Tests (some)
    /--------\
   /          \  Unit Tests (many)
  /------------\
```

### Golden Rules:
1. **Never write code without a failing test first**
2. **Write the simplest code to pass the test**
3. **Refactor only when tests are green**
4. **One test at a time**
5. **Test behavior, not implementation**

## 8. TDD Report Template

```markdown
## ðŸ§ª TDD EXECUTION REPORT

### Feature: [Name]
### Date: [Date]

### Tests Written (Before Implementation):
| # | Test Name | Expected | Status |
|---|-----------|----------|--------|
| 1 | [test 1] | [expected] | â³ |
| 2 | [test 2] | [expected] | â³ |
| 3 | [test 3] | [expected] | â³ |

### RED Phase:
- Test 1: âŒ FAIL âœ… (expected)
- Test 2: âŒ FAIL âœ… (expected)
- Test 3: âŒ FAIL âœ… (expected)

### Implementation:
[Brief description of code written]

### GREEN Phase:
- Test 1: âœ… PASS
- Test 2: âœ… PASS
- Test 3: âœ… PASS

### REFACTOR Phase:
- [Changes made]
- All tests: âœ… PASS

### Summary:
- Tests written: 3
- Tests passing: 3
- Coverage: [areas covered]
- Confidence: [X]%
```

## 9. Integration with Other Rules

### Links to Related Standards:
- `.cursor/rules/from-the-end.mdc` - Define expected output first
- `.cursor/rules/ai-qa-standards.mdc` - QA verification
- `.cursor/rules/core-check.mdc` - Test case validation

### Confidence Calibration:
```
Base: 100%
- No tests written: -60%
- Tests written but not run: -40%
- RED phase skipped: -30%
- No edge case tests: -20%
- No error case tests: -15%
```
